{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from IPython import display\n",
    "from xml.dom import minidom\n",
    "import math\n",
    "import folium\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import tqdm \n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import contextily as cx\n",
    "from random import randint\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes= gpd.read_file('Data/GIS/bus_routes/validated4-1-2023.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = []\n",
    "n = len(routes)\n",
    "\n",
    "for i in range(n):\n",
    "    color.append('#%06X' % randint(0, 0xFFFFFF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = routes.to_crs(epsg=3857).plot(figsize=(10, 10), alpha=0.50, linewidth= 3, edgecolor=color, legend= True)\n",
    "cx.add_basemap(ax, source=cx.providers.OpenStreetMap.Mapnik, zoom= 11)\n",
    "plt.xlim([3600000, 3645000])\n",
    "plt.ylim([1740000, 1780000])\n",
    "ax.set_axis_off()\n",
    "\n",
    "#plt.savefig('validated_map_.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO ###\n",
    "\n",
    "f = folium.Figure(width=800, height=800)\n",
    "\n",
    "the_map= folium.Map(location=[15.5007, 32.5599],\n",
    "                    zoom_start = 17, tiles='openstreetmap').add_to(f)\n",
    "add_all_tiles(the_map)\n",
    "\n",
    "folium.PolyLine(routes.geometry[0]).add_to(the_map_map)\n",
    "\n",
    "# Add layer control to change tiles:\n",
    "folium.LayerControl(sortLayers=True).add_to(the_map)\n",
    "\n",
    "# To store the map as a HTML page:\n",
    "# the_map.save('map_001.html')\n",
    "\n",
    "# To display the map in a Jupyter notebook:\n",
    "the_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for neighborhoods geojson\n",
    "from shapely import wkt\n",
    "\n",
    "neighborhoods= gpd.read_file('Data/GIS/other_layers/krt_neighborhoods.json')\n",
    "\n",
    "neighborhoods['PAU_NAME']= neighborhoods.PAU_NAME.str.encode('cp1252')\n",
    "neighborhoods['PAU_NAME']= neighborhoods.PAU_NAME.str.decode('cp1256')\n",
    "\n",
    "neighborhoods['Loc_Name']= neighborhoods.Loc_Name.str.encode('cp1252')\n",
    "neighborhoods['Loc_Name']= neighborhoods.Loc_Name.str.decode('cp1256')\n",
    "\n",
    "neighborhoods['AU_Name']= neighborhoods.AU_Name.str.encode('cp1252')\n",
    "neighborhoods['AU_Name']= neighborhoods.AU_Name.str.decode('cp1256')\n",
    "\n",
    "neighborhoods['PAU_NAME_1']= neighborhoods.PAU_NAME_1.str.encode('cp1252')\n",
    "neighborhoods['PAU_NAME_1']= neighborhoods.PAU_NAME_1.str.decode('cp1256')\n",
    "\n",
    "neighborhoods['Loc_Name_1']= neighborhoods.Loc_Name_1.str.encode('cp1252')\n",
    "neighborhoods['Loc_Name_1']= neighborhoods.Loc_Name_1.str.decode('cp1256')\n",
    "\n",
    "neighborhoods['AU_Name_1']= neighborhoods.AU_Name_1.str.encode('cp1252')\n",
    "neighborhoods['AU_Name_1']= neighborhoods.AU_Name_1.str.decode('cp1256')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods.columns = [x.lower() for x in neighborhoods.columns]\n",
    "neighborhoods.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = neighborhoods.plot(figsize=(10, 10), alpha=0.5, edgecolor='k')\n",
    "plt.xlim([32.00, 33.00])\n",
    "plt.ylim([15.20, 16.00])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = []\n",
    "n = len(neighborhoods)\n",
    "\n",
    "for i in range(n):\n",
    "    color.append('#%06X' % randint(0, 0xFFFFFF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neighborhoods['House_Hold']= neighborhoods.House_Hold.replace(' ', 0).astype('int')\n",
    "neighborhoods= neighborhoods.drop(neighborhoods[neighborhoods.house_hold == ' '].index.values)\n",
    "neighborhoods['house_hold']= neighborhoods.house_hold.astype('int')\n",
    "neighborhoods= neighborhoods[neighborhoods.house_hold <= 3000] #filtering out one extreme neigborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#ax = neighborhoods.to_crs(epsg=3857).plot(figsize=(20, 20), alpha=0.75, linewidth= 1, edgecolor='k', legend= True)\n",
    "ax = neighborhoods.to_crs(epsg=3857).plot(column= 'house_hold', figsize=(10, 10), alpha=0.75, cmap= 'turbo',\n",
    "                                          scheme= 'user_defined',\n",
    "                                          classification_kwds=dict(bins=[500, 1000, 1500, 2000, 2500]),\n",
    "                                          linewidth= 1, edgecolor='k', legend= True)\n",
    "cx.add_basemap(ax, source=cx.providers.OpenStreetMap.Mapnik, zoom= 11)\n",
    "plt.xlim([3595000, 3650000])\n",
    "plt.ylim([1730000, 1785000])\n",
    "ax.set_axis_off()\n",
    "\n",
    "#plt.savefig('neighborhood_map.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survey Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_excel('Data/Mobility_Survey/survey_responses.xlsx')\n",
    "#data= pd.read_csv('matched_responces.csv') #for reading processed data\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.cost.describe())\n",
    "data.cost.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.household.describe())\n",
    "data[data.household <= 15].household.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.household_youth.describe())\n",
    "data[data.household_youth <= 15].household_youth.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.subplot(1,2,1)\n",
    "sns.lineplot(x= data.Timestamp.dt.day, y= data.index.values)\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.lineplot(x= data.Timestamp.dt.hour, y= data.index.values) #Hour is in US EST (KRT - 6)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.origin.value_counts())\n",
    "print(data.destination.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['origin']= data.origin.astype('str').apply(lambda x: x.replace('أ','ا').replace('ة','ه').replace('ى','ي'))\n",
    "data['destination']= data.destination.astype('str').apply(lambda x: x.replace('أ','ا').replace('ة','ه').replace('ى','ي'))\n",
    "print(data.origin.value_counts())\n",
    "print(data.destination.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get counts\n",
    "neighborhoods.loc_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix naming\n",
    "neighborhoods.loc_name[neighborhoods.loc_name == 'بحرى شمال'] = 'بحري'\n",
    "neighborhoods['loc_name']= neighborhoods.loc_name.apply(lambda x: x.replace('أ','ا').replace('ة','ه').replace('ى','ي'))\n",
    "neighborhoods['au_name']= neighborhoods.au_name.apply(lambda x: x.replace('أ','ا').replace('ة','ه').replace('ى','ي'))\n",
    "neighborhoods.loc_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods.dropna(subset=['fid'], inplace= True)\n",
    "neighborhoods.reset_index(drop= True, inplace= True)\n",
    "neighborhoods.house_hold.hist(bins= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods.groupby(['loc_name', 'au_name'])[['fid']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial= ['الخرطوم شرق', 'اركويت جامعه', 'الكلاكلة', 'كافوري', 'صالحه', 'الأزهري', 'المهندسين', 'الدروشاب']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using difflib\n",
    "import difflib\n",
    "def string_similarity(str1, str2):\n",
    "    str1= ''.join([i for i in str1 if not i.isdigit()])\n",
    "    str2= ''.join([i for i in str2 if not i.isdigit()])\n",
    "    str2= str2.replace('أ','ا').replace('ة','ه').replace('ى','ي')\n",
    "    #str2= str2[:len(str2.partition(' ')[0])+3]\n",
    "    str1= str1.replace('أ','ا').replace('ة','ه').replace('ى','ي')[:len(str2)]\n",
    "    result =  difflib.SequenceMatcher(a=str1, b=str2)\n",
    "    return result.ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using bioalign\n",
    "from Bio.Align import PairwiseAligner\n",
    "def string_similarity_(str1, str2):\n",
    "    aligner = PairwiseAligner()\n",
    "    return aligner.score(str1, str2)/len(str2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match= []\n",
    "\n",
    "for t in range(len(trial)):\n",
    "    max_score= 0\n",
    "    max_index= 0\n",
    "    for n in range(len(neighborhoods.pau_name)):\n",
    "        score= string_similarity(neighborhoods.pau_name.iat[n], trial[t])\n",
    "#         score_au= string_similarity(neighborhoods.au_name.iat[n], trial[t])\n",
    "#         score = score_au if score_au > score else score\n",
    "        #score= string_similarity(str(neighborhoods.pau_name[n].replace('أ','ا').replace('ة','ه')),\n",
    "        #                         str(trial[t].replace('أ','ا').replace('ة','ه')))\n",
    "        #score= string_similarity(str(neighborhoods.pau_name[n].encode), str(trial[t].encode))\n",
    "        #max_score= score if score > max_score else score\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            max_index = n\n",
    "    if max_score < 0.65:\n",
    "        match.append([trial[t], 'No Match Found', round(max_score,3)])\n",
    "    else:\n",
    "        match.append([trial[t], neighborhoods.pau_name.iat[max_index], round(max_score,3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for survey data\n",
    "data['matched_origin'] = None\n",
    "data['matching_score'] = 0\n",
    "\n",
    "with tqdm.tqdm(total= len(data), position=0, leave=True) as pbar:\n",
    "    for o in range(len(data)):\n",
    "        pbar.update(1)\n",
    "        max_score= 0\n",
    "        max_index= 0\n",
    "        for n in range(len(neighborhoods.pau_name)):\n",
    "            score= string_similarity(neighborhoods.pau_name.iat[n], data.origin[o])\n",
    "#             score_au= string_similarity(neighborhoods.au_name.iat[n], data.origin[o])\n",
    "#             score = score_au if score_au > score else score\n",
    "\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                max_index = n\n",
    "        if max_score < 0.70:\n",
    "            data.at[o, 'matched_origin'] = 'No Match Found'\n",
    "        else:\n",
    "            data.at[o, 'matched_origin'] = neighborhoods.pau_name.iat[max_index]\n",
    "            data.at[o, 'matching_score'] = round(max_score,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show matching diagnostics\n",
    "print(f'Percent unmatched= {round(len(data[data.matched_origin == \"No Match Found\"])/len(data),3)*100}')\n",
    "data[['origin', 'matched_origin', 'matching_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#similarly for destinations\n",
    "#for survey data\n",
    "data['matched_destination'] = None\n",
    "data['matching_score_d'] = 0\n",
    "\n",
    "with tqdm.tqdm(total= len(data), position=0, leave=True) as pbar:\n",
    "    for o in range(len(data)):\n",
    "        pbar.update(1)\n",
    "        max_score= 0\n",
    "        max_index= 0\n",
    "        for n in range(len(neighborhoods.pau_name)):\n",
    "            score= string_similarity(neighborhoods.pau_name.iat[n], data.destination[o])\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                max_index = n\n",
    "        if max_score < 0.70:\n",
    "            data.at[o, 'matched_destination'] = 'No Match Found'\n",
    "        else:\n",
    "            data.at[o, 'matched_destination'] = neighborhoods.pau_name.iat[max_index]\n",
    "            data.at[o, 'matching_score_d'] = round(max_score,3)\n",
    "            \n",
    "print(f'Percent unmatched= {round(len(data[data.matched_destination == \"No Match Found\"])/len(data),3)*100}')\n",
    "data[['destination', 'matched_destination', 'matching_score_d']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods['survey_count'] = 0\n",
    "\n",
    "with tqdm.tqdm(total= len(neighborhoods), position= 0, leave= True) as pbar:\n",
    "    for n in range(len(neighborhoods)):\n",
    "        pbar.update(1)\n",
    "        try:\n",
    "            neighborhoods.survey_count.iat[n]= data.matched_origin.value_counts()[neighborhoods.pau_name.iat[n]]\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = neighborhoods.to_crs(epsg=3857).plot(column= 'survey_count', figsize=(15, 15), alpha=0.75, cmap= 'turbo',\n",
    "                                          scheme= 'user_defined',\n",
    "                                          classification_kwds=dict(bins=[1, 10,20,30,40,50]),\n",
    "                                          linewidth= 1, edgecolor='k', legend= True)\n",
    "cx.add_basemap(ax, source=cx.providers.OpenStreetMap.Mapnik, zoom= 11)\n",
    "plt.xlim([3595000, 3650000])\n",
    "plt.ylim([1730000, 1785000])\n",
    "ax.set_axis_off()\n",
    "\n",
    "#plt.savefig('validated_map_.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using GeoCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcd_data= data[data.matched_origin == 'No Match Found']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcd_data['location'] = gcd_data.origin+', الخرطوم, السودان'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= gpd.tools.geocode(gcd_data.location.sample(20))\n",
    "test= test.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = neighborhoods.plot(figsize=(10, 10), alpha=0.5, edgecolor='k')\n",
    "test.plot(ax=ax, c='r')\n",
    "plt.xlim([32.00, 33.00])\n",
    "plt.ylim([15.20, 16.00])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "test['pau_name'] = 'Unknown'\n",
    "with tqdm.tqdm(total= len(test), position=0, leave=True) as pbar:\n",
    "    for i in range(len(test)):\n",
    "        pbar.update(1)\n",
    "        for j in range(len(neighborhoods)):\n",
    "            try:\n",
    "                if Polygon(neighborhoods.geometry.iat[j]).contains(Point(test.geometry.iat[i])):\n",
    "                    test.pau_name.iat[i]= neighborhoods.pau_name.iat[j]\n",
    "            except:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#geocode everything\n",
    "\n",
    "counter = 0\n",
    "batch = 10\n",
    "gcd = pd.DataFrame()\n",
    "\n",
    "with tqdm.tqdm(total= np.ceil(len(gcd_data)/batch), position=0, leave=True) as pbar:\n",
    "    for i in range(int(np.ceil(len(gcd_data)/batch))):\n",
    "        pbar.update(1)\n",
    "        test= gpd.tools.geocode(gcd_data.location[counter:counter+batch])\n",
    "        gcd= pd.concat([gcd, test])\n",
    "        counter += batch\n",
    "        time.sleep(10) #break down requests\n",
    "gcd= gcd.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcd['pau_name'] = 'Unknown'\n",
    "\n",
    "with tqdm.tqdm(total= len(gcd), position=0, leave=True) as pbar:\n",
    "    for i in range(len(gcd)):\n",
    "        pbar.update(1)\n",
    "        for j in range(len(neighborhoods)):\n",
    "            try:\n",
    "                if Polygon(neighborhoods.geometry.iat[j]).contains(Point(gcd.geometry.iat[i])):\n",
    "                    gcd.pau_name.iat[i]= neighborhoods.pau_name.iat[j]\n",
    "            except:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for response in gcd.index.values:\n",
    "    data.matched_origin.at[response] = gcd.pau_name.at[response]\n",
    "    \n",
    "print(f'Percent unmatched= {round(len(data[data.matched_origin == \"Unknown\"])/len(data),3)*100}')\n",
    "data[['origin', 'matched_origin', 'matching_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods['survey_count'] = 0\n",
    "\n",
    "with tqdm.tqdm(total= len(neighborhoods), position= 0, leave= True) as pbar:\n",
    "    for n in range(len(neighborhoods)):\n",
    "        pbar.update(1)\n",
    "        try:\n",
    "            neighborhoods.survey_count.iat[n]= data.matched_origin.value_counts()[neighborhoods.pau_name.iat[n]]\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = neighborhoods.to_crs(epsg=3857).plot(column= 'survey_count', figsize=(10, 10), alpha=0.75, cmap= 'turbo',\n",
    "                                          scheme= 'user_defined',\n",
    "                                          classification_kwds=dict(bins=[1,20,30,40,50,100]),\n",
    "                                          linewidth=1, edgecolor='k', legend= True)\n",
    "cx.add_basemap(ax, source=cx.providers.OpenStreetMap.Mapnik, zoom= 11)\n",
    "plt.xlim([3595000, 3650000])\n",
    "plt.ylim([1730000, 1785000])\n",
    "ax.set_axis_off()\n",
    "\n",
    "#plt.savefig('validated_map_.jpg') #print on 20x20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes= gpd.read_file('Data/GIS/bus_routes/validated4-1-2023.json')\n",
    "\n",
    "color = []\n",
    "n = len(routes)\n",
    "\n",
    "for i in range(n):\n",
    "    color.append('#%06X' % randint(0, 0xFFFFFF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = neighborhoods.to_crs(epsg=3857).plot(column= 'survey_count', figsize=(10, 10), alpha=0.75, cmap= 'turbo',\n",
    "                                          scheme= 'user_defined',\n",
    "                                          classification_kwds=dict(bins=[1,20,30,40,50,100]),\n",
    "                                          linewidth= 0.50, edgecolor='k', legend= True)\n",
    "routes.to_crs(epsg=3857).plot(ax=ax, alpha=1.0, linewidth= 3, edgecolor=color, legend= True)\n",
    "cx.add_basemap(ax, source=cx.providers.OpenStreetMap.Mapnik, zoom= 11)\n",
    "plt.xlim([3595000, 3650000])\n",
    "plt.ylim([1730000, 1785000])\n",
    "ax.set_axis_off()\n",
    "\n",
    "#plt.savefig('routes.jpg') #print on 20x20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same thing for destinations\n",
    "#if it breaks, remove everything until creating gcd and replace tqdm total - i, i range(i,int(np.ceil...))\n",
    "\n",
    "gcd_data= data[data.matched_destination == 'No Match Found']\n",
    "gcd_data['location'] = gcd_data.destination+', الخرطوم, السودان'\n",
    "\n",
    "counter = 0\n",
    "batch = 10\n",
    "gcd = pd.DataFrame()\n",
    "print('Geocoding in Progress...')\n",
    "with tqdm.tqdm(total= np.ceil(len(gcd_data)/batch), position=0, leave=True) as pbar:\n",
    "    for i in range(int(np.ceil(len(gcd_data)/batch))):\n",
    "        pbar.update(1)\n",
    "        test= gpd.tools.geocode(gcd_data.location[counter:counter+batch])\n",
    "        gcd= pd.concat([gcd, test])\n",
    "        counter += batch\n",
    "        time.sleep(15) #break down requests\n",
    "gcd= gcd.to_crs(epsg=4326)\n",
    "gcd['pau_name'] = 'Unknown'\n",
    "\n",
    "print('Geocoding Matching...')\n",
    "with tqdm.tqdm(total= len(gcd), position=0, leave=True) as pbar:\n",
    "    for i in range(len(gcd)):\n",
    "        pbar.update(1)\n",
    "        for j in range(len(neighborhoods)):\n",
    "            try:\n",
    "                if Polygon(neighborhoods.geometry.iat[j]).contains(Point(gcd.geometry.iat[i])):\n",
    "                    gcd.pau_name.iat[i]= neighborhoods.pau_name.iat[j]\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "for response in gcd.index.values:\n",
    "    data.matched_destination.at[response] = gcd.pau_name.at[response]\n",
    "print(f'Percent unmatched= {round(len(data[data.matched_destination == \"Unknown\"])/len(data),3)*100}')\n",
    "data[['destination', 'matched_destination', 'matching_score']]\n",
    "\n",
    "print('Counting...')\n",
    "neighborhoods['survey_count'] = 0\n",
    "with tqdm.tqdm(total= len(neighborhoods), position= 0, leave= True) as pbar:\n",
    "    for n in range(len(neighborhoods)):\n",
    "        pbar.update(1)\n",
    "        try:\n",
    "            neighborhoods.survey_count.iat[n]= data.matched_destination.value_counts()[neighborhoods.pau_name.iat[n]]\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "print('Plotting...')           \n",
    "ax = neighborhoods.to_crs(epsg=3857).plot(column= 'survey_count', figsize=(10, 10), alpha=0.75, cmap= 'turbo',\n",
    "                                          scheme= 'user_defined',\n",
    "                                          classification_kwds=dict(bins=[1,10,25,50,100,250]),\n",
    "                                          linewidth= 1, edgecolor='k', legend= True)\n",
    "cx.add_basemap(ax, source=cx.providers.OpenStreetMap.Mapnik, zoom= 11)\n",
    "plt.xlim([3595000, 3650000])\n",
    "plt.ylim([1730000, 1785000])\n",
    "ax.set_axis_off()\n",
    "\n",
    "#plt.savefig('validated_map_.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('matched_responces.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= data.groupby(['matched_origin', 'matched_destination'])[['per_day']].count()\n",
    "x.reset_index(inplace= True)\n",
    "x.sort_values('per_day', ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= data.groupby(['origin_locality', 'destination_locality'])[['per_day']].count()\n",
    "x.reset_index(inplace= True)\n",
    "x.sort_values('per_day', ascending= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
